{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SH_eVdlES6w0"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets==3.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "Pe4gc0W8TPEO",
        "outputId": "8b3303a5-4443-4abc-9228-ef495e58929e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==3.6.0\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-3.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets"
                ]
              },
              "id": "b795b3b698e545e8b2bc3bdcc95056e3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fleurs = load_dataset(\"google/fleurs\", \"ru_ru\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Pl-qFNTIrw",
        "outputId": "79b30fab-f43f-4ddd-d189-21748300a2de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fleurs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9hKi1hlVEYb",
        "outputId": "d5c3efd8-9f07-465c-bf5c-3f3b9d591edb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
              "        num_rows: 2562\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
              "        num_rows: 356\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
              "        num_rows: 775\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --no-deps git+https://github.com/salute-developers/GigaAM.git pywer hydra-core kenlm flashlight-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2oLjW8RVkyK",
        "outputId": "3be969d5-0279-4f8b-e6d0-d898f7cf6cad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/salute-developers/GigaAM.git\n",
            "  Cloning https://github.com/salute-developers/GigaAM.git to /tmp/pip-req-build-y8fb3nw7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/salute-developers/GigaAM.git /tmp/pip-req-build-y8fb3nw7\n",
            "  Resolved https://github.com/salute-developers/GigaAM.git to commit 6a8b511f753670ed38af6529bb89bbdc2191ba6a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pywer\n",
            "  Downloading pywer-0.1.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting kenlm\n",
            "  Downloading kenlm-0.3.0.tar.gz (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.5/427.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flashlight-text\n",
            "  Downloading flashlight_text-0.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Downloading pywer-0.1.1-py3-none-any.whl (3.6 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flashlight_text-0.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gigaam, kenlm\n",
            "  Building wheel for gigaam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gigaam: filename=gigaam-0.1.0-py3-none-any.whl size=22491 sha256=6e71df7ffc4145e6bf434d1187f58c0d70595a576b4edace701cfb105941d963\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-34xiqpfz/wheels/22/24/9c/7ab61a789d64bf3684c9929ae3128bf8dc1851b7b642478eb7\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.3.0-cp312-cp312-linux_x86_64.whl size=3188053 sha256=3bc5579cf2952bb534fa92fc085a861654d8358dc568b881437c20031f7e82f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/e6/ad/18d2d3f1290a6be6a14a24e90f2b78bb3300aab3852ceb06a6\n",
            "Successfully built gigaam kenlm\n",
            "Installing collected packages: kenlm, hydra-core, pywer, gigaam, flashlight-text\n",
            "Successfully installed flashlight-text-0.0.7 gigaam-0.1.0 hydra-core-1.3.2 kenlm-0.3.0 pywer-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import gigaam"
      ],
      "metadata": {
        "id": "jtfIRuUuWG2s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gigaam import GigaAMASR\n",
        "\n",
        "CACHE_DIR = os.path.expanduser(\"~/.cache/gigaam\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_name, model_path = gigaam._download_model('ctc', CACHE_DIR)\n",
        "\n",
        "ckpt = torch.load(model_path, map_location='cpu', weights_only=False)\n",
        "\n",
        "ckpt[\"cfg\"].encoder.flash_attn = False\n",
        "model = GigaAMASR(ckpt['cfg'])\n",
        "\n",
        "model.load_state_dict(ckpt[\"state_dict\"], strict=False)\n",
        "model = model.eval()\n",
        "\n",
        "if device.type != \"cpu\":\n",
        "  model.encoder = model.encoder.half()\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "WCb1KEiFVqD8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "import torchaudio\n",
        "from typing import Tuple\n",
        "\n",
        "class SpecScaler(nn.Module):\n",
        "    \"\"\"\n",
        "    Module that applies logarithmic scaling to spectrogram values.\n",
        "    This module clamps the input values within a certain range and then applies a natural logarithm.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return torch.log(x.clamp_(1e-9, 1e9))\n",
        "\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    Module for extracting Log-mel spectrogram features from raw audio signals.\n",
        "    This module uses Torchaudio's MelSpectrogram transform to extract features\n",
        "    and applies logarithmic scaling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sample_rate: int, features: int):\n",
        "        super().__init__()\n",
        "        self.hop_length = sample_rate // 100\n",
        "        self.featurizer = nn.Sequential(\n",
        "            torchaudio.transforms.MelSpectrogram(\n",
        "                sample_rate=sample_rate,\n",
        "                n_fft=sample_rate // 40,\n",
        "                win_length=sample_rate // 40,\n",
        "                hop_length=self.hop_length,\n",
        "                n_mels=features,\n",
        "            ),\n",
        "            SpecScaler(),\n",
        "        )\n",
        "\n",
        "    def out_len(self, input_lengths: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Calculates the output length after the feature extraction process.\n",
        "        \"\"\"\n",
        "        return input_lengths.div(self.hop_length, rounding_mode=\"floor\").add(1).long()\n",
        "\n",
        "    def forward(self, input_signal: Tensor, length: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Extract Log-mel spectrogram features from the input audio signal.\n",
        "        \"\"\"\n",
        "        return self.featurizer(input_signal), self.out_len(length)"
      ],
      "metadata": {
        "id": "8FFk--XRWRRc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import Dict\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Датасет для загрузки аудиофайлов и транскрипций\n",
        "\n",
        "    Ожидаемый формат данных:\n",
        "    - manifest_path: путь к JSON файлу с метаданными\n",
        "    - Формат JSON: [{\"audio_path\": \"path/to/audio.wav\", \"text\": \"транскрипция\"}, ...]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, preprocessor):\n",
        "       self.dataset = dataset\n",
        "       self.preprocessor = preprocessor\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict:\n",
        "        sample = self.dataset[idx]\n",
        "\n",
        "        # mel_spec_signal, signal_len = self.preprocessor(\n",
        "        #    torch.tensor(sample['audio']['array'], dtype=torch.float32),\n",
        "        #    torch.tensor(sample['num_samples'], dtype=torch.int32)\n",
        "        # )\n",
        "\n",
        "        # return {\n",
        "        #     'audio': mel_spec_signal,\n",
        "        #     'num_samples': signal_len,\n",
        "        #     'transcription': sample['transcription'],\n",
        "        # }\n",
        "\n",
        "        return {\n",
        "            'audio': torch.tensor(sample['audio']['array'], dtype=torch.float32),\n",
        "            'num_samples': torch.tensor(sample['num_samples'], dtype=torch.int32),\n",
        "            'transcription': sample['transcription'],\n",
        "        }"
      ],
      "metadata": {
        "id": "biAuPEB_Wul8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    # Для полей с разной длиной (например, audio) нужно добавить паддинг\n",
        "    audio = [item['audio'] for item in batch]\n",
        "    audio_padded = torch.nn.utils.rnn.pad_sequence(audio, batch_first=True)\n",
        "\n",
        "    return audio_padded, torch.stack([item['num_samples'] for item in batch]), [item['transcription'] for item in batch]"
      ],
      "metadata": {
        "id": "kWCNzH3DW-8r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = AudioDataset(fleurs['train'], preprocessor=FeatureExtractor(sample_rate=16000, features=64))"
      ],
      "metadata": {
        "id": "Pqt8_x6VXKuX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=1,\n",
        "            shuffle=True,\n",
        "            num_workers=1,\n",
        "            collate_fn=collate_fn,\n",
        "        )"
      ],
      "metadata": {
        "id": "LxFTMnYcXFMY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "  audio, num_samples, texts = batch\n",
        "  print(audio)\n",
        "  print(num_samples)\n",
        "  print(texts)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSPMYlQEXPxi",
        "outputId": "e60b3fe0-f5b6-4d6c-9c03-8e5bf676d9a9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e47a5d5cf40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0002, -0.0001, -0.0002]])\n",
            "tensor([148800], dtype=torch.int32)\n",
            "['однако люди которые знают немного испанский язык могут поспешно заключить что португальский язык достаточно схож и его можно не учить отдельно']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gigaam_logprobs(model, wav_batch, wav_lengths, return_transcriptions=False):\n",
        "    wav_batch = wav_batch.to(model._device)\n",
        "    wav_lengths = wav_lengths.to(model._device)\n",
        "\n",
        "    encoded, encoded_len = model.forward(wav_batch, wav_lengths)\n",
        "\n",
        "    logprobs = model.head(encoded)\n",
        "\n",
        "    if return_transcriptions:\n",
        "        transcriptions = model.decoding.decode(model.head, encoded, encoded_len)\n",
        "        return logprobs, encoded_len, transcriptions\n",
        "    else:\n",
        "        return logprobs, encoded_len"
      ],
      "metadata": {
        "id": "9LtUFWHZYnZi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import encode_long\n",
        "def compute_ctc_loss(wav_batch, wav_lengths, transcripts, transcript_lengths):\n",
        "        # Получаем логиты от модели\n",
        "        logprobs, encoded_len = get_gigaam_logprobs(model, wav_batch, wav_lengths)\n",
        "\n",
        "        # print(f\"[DEBUG] {encoded_len}\")\n",
        "        encoded_len = tuple(encoded_len.numpy())\n",
        "        # print(f\"[DEBUG] {encoded_len}\")\n",
        "\n",
        "        # CTCLoss требует логиты в формате (T, N, C)\n",
        "        # Где T - временная длина, N - размер батча, C - число классов\n",
        "        logprobs = logprobs.transpose(0, 1)  # Теперь форма (T, N, C)\n",
        "\n",
        "        # Инициализируем CTC Loss\n",
        "        # ctc_loss = nn.CTCLoss(blank=self.model.decoding.blank_id, reduction='mean', zero_infinity=True)\n",
        "        #! Here can be an error\n",
        "        BLANK_IDX = 33\n",
        "        ctc_loss = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True)\n",
        "\n",
        "        # print(f\"[DEBUG] logprobs len {len(logprobs)}\")\n",
        "        # print(f\"[DEBUG] transcription length {len(transcripts[0])}\")\n",
        "        # Вычисляем потерю\n",
        "        loss = ctc_loss(\n",
        "            logprobs,           # (T, N, C)\n",
        "            transcripts,        # (N, S) -> целочисленные индексы\n",
        "            encoded_len,        # (N,) -> длины выходных последовательностей\n",
        "            transcript_lengths  # (N,) -> длины целевых последовательностей\n",
        "        )\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "EqQfOmEDYmNY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.decoding.blank_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgUhLNwtefgZ",
        "outputId": "272b0f55-0c36-492a-ba6e-617e8578a4be"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.decoding.tokenizer.vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPcHTPVyelbh",
        "outputId": "4893ad47-c399-4a2c-98af-e38b65d521e5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_vocab = {sym: idx for idx, sym in enumerate(model.decoding.tokenizer.vocab)}"
      ],
      "metadata": {
        "id": "rOztOyn8eodr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Предобрабатывает текст по заданным правилам:\n",
        "    1. Оставляет только символы русского алфавита и пробелы\n",
        "    2. Заменяет дефисы на пробелы\n",
        "    3. Заменяет латинские буквы на близкие русские\n",
        "    4. Заменяет арабские и римские цифры на слова\n",
        "    \"\"\"\n",
        "\n",
        "    # Словарь замены латинских букв на русские\n",
        "    latin_to_russian = {\n",
        "        'a': 'а', 'A': 'А',\n",
        "        'b': 'б', 'B': 'Б',\n",
        "        'c': 'к', 'C': 'К',\n",
        "        'd': 'д', 'D': 'Д',\n",
        "        'e': 'е', 'E': 'Е',\n",
        "        'f': 'ф', 'F': 'Ф',\n",
        "        'g': 'г', 'G': 'Г',\n",
        "        'h': 'х', 'H': 'Х',\n",
        "        'i': 'и', 'I': 'И',\n",
        "        'j': 'й', 'J': 'Й',\n",
        "        'k': 'к', 'K': 'К',\n",
        "        'l': 'л', 'L': 'Л',\n",
        "        'm': 'м', 'M': 'М',\n",
        "        'n': 'н', 'N': 'Н',\n",
        "        'o': 'о', 'O': 'О',\n",
        "        'p': 'п', 'P': 'П',\n",
        "        'q': 'к', 'Q': 'К',\n",
        "        'r': 'р', 'R': 'Р',\n",
        "        's': 'с', 'S': 'С',\n",
        "        't': 'т', 'T': 'Т',\n",
        "        'u': 'у', 'U': 'У',\n",
        "        'v': 'в', 'V': 'В',\n",
        "        'w': 'в', 'W': 'В',\n",
        "        'x': 'кс', 'X': 'Кс',\n",
        "        'y': 'у', 'Y': 'У',\n",
        "        'z': 'з', 'Z': 'З'\n",
        "    }\n",
        "\n",
        "    # Словарь для замены арабских цифр\n",
        "    digit_to_word = {\n",
        "        '0': 'ноль',\n",
        "        '1': 'один',\n",
        "        '2': 'два',\n",
        "        '3': 'три',\n",
        "        '4': 'четыре',\n",
        "        '5': 'пять',\n",
        "        '6': 'шесть',\n",
        "        '7': 'семь',\n",
        "        '8': 'восемь',\n",
        "        '9': 'девять'\n",
        "    }\n",
        "\n",
        "    # Словарь для замены римских цифр\n",
        "    roman_to_word = {\n",
        "        'I': 'один', 'II': 'два', 'III': 'три', 'IV': 'четыре', 'V': 'пять',\n",
        "        'VI': 'шесть', 'VII': 'семь', 'VIII': 'восемь', 'IX': 'девять', 'X': 'десять',\n",
        "        'XI': 'одиннадцать', 'XII': 'двенадцать', 'XIII': 'тринадцать',\n",
        "        'XIV': 'четырнадцать', 'XV': 'пятнадцать', 'XVI': 'шестнадцать',\n",
        "        'XVII': 'семнадцать', 'XVIII': 'восемнадцать', 'XIX': 'девятнадцать',\n",
        "        'XX': 'двадцать'\n",
        "    }\n",
        "\n",
        "    # Приводим текст к нижнему регистру для удобства обработки\n",
        "    text = text.lower()\n",
        "\n",
        "    # Заменяем римские цифры (обрабатываем сначала перед другими преобразованиями)\n",
        "    for roman, word in sorted(roman_to_word.items(), key=lambda x: len(x[0]), reverse=True):\n",
        "        text = re.sub(r'\\b' + roman + r'\\b', word, text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Заменяем латинские буквы на русские\n",
        "    for latin, russian in latin_to_russian.items():\n",
        "        text = text.replace(latin, russian)\n",
        "\n",
        "    # Заменяем арабские цифры\n",
        "    for digit, word in digit_to_word.items():\n",
        "        text = text.replace(digit, word)\n",
        "\n",
        "    # Заменяем дефисы на пробелы\n",
        "    text = text.replace('-', ' ')\n",
        "\n",
        "    # Удаляем все символы, кроме русских букв и пробелов\n",
        "    text = re.sub(r'[^а-я\\s]', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Убираем лишние пробелы\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "Fy5dfk72pf4n"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Any\n",
        "\n",
        "def get_texts_idxs(texts: List[str]) -> torch.Tensor:\n",
        "  texts_idxs = []\n",
        "  for text in texts:\n",
        "    print(f\"[DEBUG] {text}\")\n",
        "\n",
        "    text = preprocess_text(text)\n",
        "\n",
        "    print(f\"[DEBUG] preprocessed text: {text}\")\n",
        "\n",
        "    text_idxs = [model_vocab[sym] for sym in text]\n",
        "    texts_idxs.append(text_idxs)\n",
        "\n",
        "  return torch.tensor(texts_idxs, dtype=torch.int)"
      ],
      "metadata": {
        "id": "xvgWv8wKgJhY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "  audio, num_samples, texts = batch\n",
        "\n",
        "  transcript_lengths=(len(sample) for sample in texts)\n",
        "  loss = compute_ctc_loss(\n",
        "            audio,\n",
        "            num_samples,\n",
        "            get_texts_idxs(texts),\n",
        "            transcript_lengths=tuple(transcript_lengths)\n",
        "        )\n",
        "  print(loss)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej7ZIgvpYrNd",
        "outputId": "c86d83bb-0db9-4028-ed2e-0a814840d47e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] карно является знаменитым учителем английского со спорной репутацией он преподавал в учебных заведениях современное образование и королевская слава и заявлял что на пике карьеры у него было 9000 учащихся\n",
            "[DEBUG] preprocessed text: карно является знаменитым учителем английского со спорной репутацией он преподавал в учебных заведениях современное образование и королевская слава и заявлял что на пике карьеры у него было девятьнольнольноль учащихся\n",
            "tensor(1.2369, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    }
  ]
}